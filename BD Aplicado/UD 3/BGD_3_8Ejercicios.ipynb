{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CkMrsp85SQ4"
      },
      "source": [
        "# EJERCICIOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LuecDqKh5SRT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import lit, current_date, year, monotonically_increasing_id,  avg, min, coalesce\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"pyspark_rdd\").getOrCreate()\n",
        "#spark = SparkSession.builder.getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxPbn7ct5SRW"
      },
      "source": [
        "## EJERCICIO 0\n",
        "En un documento word haz una lista de las diferentes operaciones con una breve descripción de lo que hace y un ejemplo de como se utiliza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Operaciones comunes con DataFrames en Spark\n",
        "\n",
        "## 1. **Creación de un DataFrame**\n",
        "   - **Descripción**: Crear un DataFrame a partir de una lista, un RDD, o una fuente de datos externa como un archivo CSV, JSON, etc.\n",
        "   - **Ejemplo**:\n",
        "     ```python\n",
        "     from pyspark.sql import SparkSession\n",
        "\n",
        "     spark = SparkSession.builder.appName(\"example\").getOrCreate()\n",
        "     data = [(\"Alice\", 34), (\"Bob\", 45), (\"Cathy\", 29)]\n",
        "     columns = [\"Name\", \"Age\"]\n",
        "     df = spark.createDataFrame(data, columns)\n",
        "     df.show()\n",
        "     ```\n",
        "\n",
        "## 2. **Selección de columnas**\n",
        "   - **Descripción**: Seleccionar una o más columnas de un DataFrame.\n",
        "   - **Ejemplo**:\n",
        "     ```python\n",
        "     df.select(\"Name\").show()\n",
        "     ```\n",
        "\n",
        "## 3. **Filtrado de filas**\n",
        "   - **Descripción**: Filtrar filas basadas en una condición.\n",
        "   - **Ejemplo**:\n",
        "     ```python\n",
        "     df.filter(df[\"Age\"] > 30).show()\n",
        "     ```\n",
        "\n",
        "## 4. **Agregación**\n",
        "   - **Descripción**: Realizar operaciones de agregación como `count`, `sum`, `avg`, `min`, `max`, etc.\n",
        "   - **Ejemplo**:\n",
        "     ```python\n",
        "     from pyspark.sql import functions as F\n",
        "\n",
        "     df.agg(F.max(\"Age\")).show()\n",
        "     ```\n",
        "\n",
        "## 5. **Ordenación**\n",
        "   - **Descripción**: Ordenar el DataFrame por una o más columnas.\n",
        "   - **Ejemplo**:\n",
        "     ```python\n",
        "     df.orderBy(\"Age\", ascending=False).show()\n",
        "     ```\n",
        "\n",
        "## 6. **Agrupación**\n",
        "   - **Descripción**: Agrupar datos basados en una o más columnas y luego aplicar una función de agregación.\n",
        "   - **Ejemplo**:\n",
        "     ```python\n",
        "     df.groupBy(\"Name\").agg(F.sum(\"Age\")).show()\n",
        "     ```\n",
        "\n",
        "## 7. **Unión de DataFrames**\n",
        "   - **Descripción**: Unir dos DataFrames verticalmente (añadir filas).\n",
        "   - **Ejemplo**:\n",
        "     ```python\n",
        "     df2 = spark.createDataFrame([(\"David\", 50)], columns)\n",
        "     df.union(df2).show()\n",
        "     ```\n",
        "\n",
        "## 8. **Join de DataFrames**\n",
        "   - **Descripción**: Unir dos DataFrames horizontalmente basado en una clave común.\n",
        "   - **Ejemplo**:\n",
        "     ```python\n",
        "     df3 = spark.createDataFrame([(\"Alice\", \"Engineer\"), (\"Bob\", \"Doctor\")], [\"Name\", \"Profession\"])\n",
        "     df.join(df3, on=\"Name\", how=\"inner\").show()\n",
        "     ```\n",
        "\n",
        "## 9. **Renombrar columnas**\n",
        "   - **Descripción**: Cambiar el nombre de una o más columnas.\n",
        "   - **Ejemplo**:\n",
        "     ```python\n",
        "     df.withColumnRenamed(\"Age\", \"Years\").show()\n",
        "     ```\n",
        "\n",
        "## 10. **Añadir una nueva columna**\n",
        "  - **Descripción**: Añadir una nueva columna basada en una expresión o transformación.\n",
        "    - **Ejemplo**:\n",
        "      ```python\n",
        "      df = df.withColumn(\"AgePlus10\", df[\"Age\"] + 10)\n",
        "      df.show()\n",
        "      ```\n",
        "\n",
        "## 11. **Eliminar columnas**\n",
        "  - **Descripción**: Eliminar una o más columnas del DataFrame.\n",
        "    - **Ejemplo**:\n",
        "      ```python\n",
        "      df = df.drop(\"AgePlus10\")\n",
        "      df.show()\n",
        "      ```\n",
        "\n",
        "## 12. **Distinct**\n",
        "  - **Descripción**: Obtener filas únicas basadas en todas las columnas o un subconjunto de columnas.\n",
        "    - **Ejemplo**:\n",
        "      ```python\n",
        "      df.select(\"Name\").distinct().show()\n",
        "      ```\n",
        "\n",
        "## 13. **Persistencia (Caching)**\n",
        "  - **Descripción**: Almacenar en caché un DataFrame para mejorar el rendimiento en operaciones repetitivas.\n",
        "    - **Ejemplo**:\n",
        "      ```python\n",
        "      df.cache()\n",
        "      df.count()  # Para materializar el caché\n",
        "      ```\n",
        "\n",
        "## 14. **Escritura en disco**\n",
        "  - **Descripción**: Guardar un DataFrame en un archivo (CSV, JSON, Parquet, etc.).\n",
        "    - **Ejemplo**:\n",
        "      ```python\n",
        "      df.write.csv(\"output.csv\", header=True)\n",
        "      ```\n",
        "\n",
        "## 15. **Lectura desde disco**\n",
        "  - **Descripción**: Leer un DataFrame desde un archivo (CSV, JSON, Parquet, etc.).\n",
        "    - **Ejemplo**:\n",
        "      ```python\n",
        "      df = spark.read.csv(\"output.csv\", header=True, inferSchema=True)\n",
        "      df.show()\n",
        "      ```\n",
        "\n",
        "## 16. **Explode**\n",
        "  - **Descripción**: Convertir una columna de tipo array o map en múltiples filas.\n",
        "    - **Ejemplo**:\n",
        "      ```python\n",
        "      from pyspark.sql.functions import explode\n",
        "\n",
        "      data = [(\"Alice\", [1, 2, 3]), (\"Bob\", [4, 5])]\n",
        "      columns = [\"Name\", \"Numbers\"]\n",
        "      df = spark.createDataFrame(data, columns)\n",
        "      df.withColumn(\"Number\", explode(\"Numbers\")).show()\n",
        "      ```\n",
        "\n",
        "## 17. **UDF (User Defined Functions)**\n",
        "  - **Descripción**: Definir y utilizar una función personalizada en Spark.\n",
        "    - **Ejemplo**:\n",
        "      ```python\n",
        "      from pyspark.sql.functions import udf\n",
        "      from pyspark.sql.types import IntegerType\n",
        "\n",
        "      def square(x):\n",
        "          return x * x\n",
        "\n",
        "      square_udf = udf(square, IntegerType())\n",
        "      df.withColumn(\"AgeSquared\", square_udf(df[\"Age\"])).show()\n",
        "      ```\n",
        "\n",
        "## 18. **Window Functions**\n",
        "  - **Descripción**: Realizar operaciones sobre una ventana de filas (por ejemplo, ranking, sumas acumulativas).\n",
        "    - **Ejemplo**:\n",
        "      ```python\n",
        "      from pyspark.sql.window import Window\n",
        "      from pyspark.sql.functions import row_number\n",
        "\n",
        "      windowSpec = Window.orderBy(\"Age\")\n",
        "      df.withColumn(\"row_number\", row_number().over(windowSpec)).show()\n",
        "      ```\n",
        "\n",
        "## 19. **Pivot**\n",
        "  - **Descripción**: Convertir valores de una columna en múltiples columnas (pivote).\n",
        "    - **Ejemplo**:\n",
        "      ```python\n",
        "      data = [(\"Alice\", \"Math\", 80), (\"Alice\", \"Science\", 90), (\"Bob\", \"Math\", 85)]\n",
        "      columns = [\"Name\", \"Subject\", \"Score\"]\n",
        "      df = spark.createDataFrame(data, columns)\n",
        "      df.groupBy(\"Name\").pivot(\"Subject\").avg(\"Score\").show()\n",
        "      ```\n",
        "\n",
        "## 20. **Describe**\n",
        "  - **Descripción**: Obtener estadísticas descriptivas de las columnas numéricas.\n",
        "    - **Ejemplo**:\n",
        "      ```python\n",
        "      df.describe().show()\n",
        "      ```\n",
        "\n",
        "## 21. **Drop Duplicates**\n",
        "  - **Descripción**: Eliminar filas duplicadas basadas en todas las columnas o un subconjunto de columnas.\n",
        "    - **Ejemplo**:\n",
        "      ```python\n",
        "      df.dropDuplicates([\"Name\"]).show()\n",
        "      ```\n",
        "\n",
        "## 22. **Alias**\n",
        "  - **Descripción**: Asignar un alias a una columna o tabla.\n",
        "    - **Ejemplo**:\n",
        "      ```python\n",
        "      df.select(df[\"Name\"].alias(\"Nombre\")).show()\n",
        "      ```\n",
        "\n",
        "## 23. **Collect**\n",
        "  - **Descripción**: Recopilar todas las filas del DataFrame como una lista en el driver.\n",
        "    - **Ejemplo**:\n",
        "      ```python\n",
        "      rows = df.collect()\n",
        "      for row in rows:\n",
        "          print(row)\n",
        "      ```\n",
        "\n",
        "## 24. **Take**\n",
        "  - **Descripción**: Obtener un número específico de filas del DataFrame.\n",
        "    - **Ejemplo**:\n",
        "      ```python\n",
        "      rows = df.take(2)\n",
        "      for row in rows:\n",
        "          print(row)\n",
        "      ```\n",
        "\n",
        "## 25. **Schema**\n",
        "  - **Descripción**: Obtener el esquema del DataFrame.\n",
        "    - **Ejemplo**:\n",
        "      ```python\n",
        "      df.printSchema()\n",
        "      ```\n",
        "\n",
        "## 26. **WithColumn**\n",
        "  - **Descripción**: Añadir o reemplazar una columna en el DataFrame.\n",
        "    - **Ejemplo**:\n",
        "      ```python\n",
        "      df = df.withColumn(\"AgePlus10\", df[\"Age\"] + 10)\n",
        "      df.show()\n",
        "      ```\n",
        "\n",
        "## 27. **Cast**\n",
        "  - **Descripción**: Cambiar el tipo de datos de una columna.\n",
        "    - **Ejemplo**:\n",
        "      ```python\n",
        "      from pyspark.sql.functions import col\n",
        "\n",
        "      df = df.withColumn(\"Age\", col(\"Age\").cast(\"String\"))\n",
        "      df.printSchema()\n",
        "      ```\n",
        "\n",
        "## 28. **Sample**\n",
        "   - **Descripción**: Obtener una muestra aleatoria de filas del DataFrame.\n",
        "    - **Ejemplo**:\n",
        "      ```python\n",
        "      df.sample(0.5).show()\n",
        "      ```\n",
        "\n",
        "## 29. **Repartition**\n",
        "   - **Descripción**: Cambiar el número de particiones del DataFrame.\n",
        "    - **Ejemplo**:\n",
        "      ```python\n",
        "      df = df.repartition(4)\n",
        "      print(df.rdd.getNumPartitions())\n",
        "      ```\n",
        "\n",
        "## 30. **Coalesce**\n",
        "  - **Descripción**: Reducir el número de particiones del DataFrame.\n",
        "    - **Ejemplo**:\n",
        "      ```python\n",
        "      df = df.coalesce(2)\n",
        "      print(df.rdd.getNumPartitions())\n",
        "      ```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2ywlD0T5SRX"
      },
      "source": [
        "## EJERCICIO 1\n",
        "Realiza las siguientes operaciones:\n",
        "* Importa el csv de \"data/WorldCupPlayers.csv\" (que deduzca el esquema)\n",
        "* Visualiza los datos\n",
        "* ¿Que tipo de datos contiene cada variable?\n",
        "* ¿Cuantos registros hay?\n",
        "* Obtén los principales estadísticos de Position\n",
        "* Selecciona y muestra los \"Team initials\" diferentes que hay ¿Cuántos hay?\n",
        "* ¿Cuantos partidos con el ID de 1096 ha habido?\n",
        "* Muestra los datos donde la posicion haya sido C y el evento sea G40\n",
        "* Utiliza Spark SQL para mostras los registros donde el MatchID sea mayor o igual a 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QnmFQq55SRX",
        "outputId": "cbfb95e7-dd96-40bf-c9fe-80a07a6bad62"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/02/10 20:32:48 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Visualización de los datos:\n",
            "+-------+-------+-------------+-------------------+-------+------------+----------------+--------+-----+\n",
            "|RoundID|MatchID|Team Initials|         Coach Name|Line-up|Shirt Number|     Player Name|Position|Event|\n",
            "+-------+-------+-------------+-------------------+-------+------------+----------------+--------+-----+\n",
            "|    201|   1096|          FRA|CAUDRON Raoul (FRA)|      S|           0|     Alex THEPOT|      GK| NULL|\n",
            "|    201|   1096|          MEX|   LUQUE Juan (MEX)|      S|           0| Oscar BONFIGLIO|      GK| NULL|\n",
            "|    201|   1096|          FRA|CAUDRON Raoul (FRA)|      S|           0|Marcel LANGILLER|    NULL| G40'|\n",
            "|    201|   1096|          MEX|   LUQUE Juan (MEX)|      S|           0|    Juan CARRENO|    NULL| G70'|\n",
            "|    201|   1096|          FRA|CAUDRON Raoul (FRA)|      S|           0| Ernest LIBERATI|    NULL| NULL|\n",
            "+-------+-------+-------------+-------------------+-------+------------+----------------+--------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "Esquema del DataFrame:\n",
            "root\n",
            " |-- RoundID: integer (nullable = true)\n",
            " |-- MatchID: integer (nullable = true)\n",
            " |-- Team Initials: string (nullable = true)\n",
            " |-- Coach Name: string (nullable = true)\n",
            " |-- Line-up: string (nullable = true)\n",
            " |-- Shirt Number: integer (nullable = true)\n",
            " |-- Player Name: string (nullable = true)\n",
            " |-- Position: string (nullable = true)\n",
            " |-- Event: string (nullable = true)\n",
            "\n",
            "\n",
            "Número de registros: 37784\n",
            "\n",
            "Estadísticos de la columna 'Position':\n",
            "+-------+--------+\n",
            "|summary|Position|\n",
            "+-------+--------+\n",
            "|  count|    4143|\n",
            "|   mean|    NULL|\n",
            "| stddev|    NULL|\n",
            "|    min|       C|\n",
            "|    max|     GKC|\n",
            "+-------+--------+\n",
            "\n",
            "\n",
            "Valores únicos de 'Team Initials':\n",
            "+-------------+\n",
            "|Team Initials|\n",
            "+-------------+\n",
            "|          POL|\n",
            "|          JAM|\n",
            "|          BRA|\n",
            "|          CUB|\n",
            "|          FRA|\n",
            "|          ALG|\n",
            "|          BOL|\n",
            "|          RSA|\n",
            "|          ITA|\n",
            "|          UKR|\n",
            "|          CMR|\n",
            "|          SCG|\n",
            "|          GHA|\n",
            "|          SEN|\n",
            "|          TOG|\n",
            "|          TRI|\n",
            "|          TCH|\n",
            "|          AUS|\n",
            "|          MEX|\n",
            "|          PAR|\n",
            "+-------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "\n",
            "Número de 'Team Initials' diferentes: 82\n",
            "\n",
            "Número de partidos con el ID 1096: 33\n",
            "\n",
            "Datos filtrados donde Position es 'C' y Event es 'G40':\n",
            "+-------+-------+-------------+----------+-------+------------+-----------+--------+-----+\n",
            "|RoundID|MatchID|Team Initials|Coach Name|Line-up|Shirt Number|Player Name|Position|Event|\n",
            "+-------+-------+-------------+----------+-------+------------+-----------+--------+-----+\n",
            "+-------+-------+-------------+----------+-------+------------+-----------+--------+-----+\n",
            "\n",
            "\n",
            "Registros con MatchID mayor o igual a 20:\n",
            "+-------+-------+-------------+-------------------+-------+------------+-----------------+--------+---------+\n",
            "|RoundID|MatchID|Team Initials|         Coach Name|Line-up|Shirt Number|      Player Name|Position|    Event|\n",
            "+-------+-------+-------------+-------------------+-------+------------+-----------------+--------+---------+\n",
            "|    201|   1096|          FRA|CAUDRON Raoul (FRA)|      S|           0|      Alex THEPOT|      GK|     NULL|\n",
            "|    201|   1096|          MEX|   LUQUE Juan (MEX)|      S|           0|  Oscar BONFIGLIO|      GK|     NULL|\n",
            "|    201|   1096|          FRA|CAUDRON Raoul (FRA)|      S|           0| Marcel LANGILLER|    NULL|     G40'|\n",
            "|    201|   1096|          MEX|   LUQUE Juan (MEX)|      S|           0|     Juan CARRENO|    NULL|     G70'|\n",
            "|    201|   1096|          FRA|CAUDRON Raoul (FRA)|      S|           0|  Ernest LIBERATI|    NULL|     NULL|\n",
            "|    201|   1096|          MEX|   LUQUE Juan (MEX)|      S|           0|     Rafael GARZA|       C|     NULL|\n",
            "|    201|   1096|          FRA|CAUDRON Raoul (FRA)|      S|           0|  Andre MASCHINOT|    NULL|G43' G87'|\n",
            "|    201|   1096|          MEX|   LUQUE Juan (MEX)|      S|           0|    Hilario LOPEZ|    NULL|     NULL|\n",
            "|    201|   1096|          FRA|CAUDRON Raoul (FRA)|      S|           0|  Etienne MATTLER|    NULL|     NULL|\n",
            "|    201|   1096|          MEX|   LUQUE Juan (MEX)|      S|           0|   Dionisio MEJIA|    NULL|     NULL|\n",
            "|    201|   1096|          FRA|CAUDRON Raoul (FRA)|      S|           0|     Marcel PINEL|    NULL|     NULL|\n",
            "|    201|   1096|          MEX|   LUQUE Juan (MEX)|      S|           0|     Felipe ROSAS|    NULL|     NULL|\n",
            "|    201|   1096|          FRA|CAUDRON Raoul (FRA)|      S|           0|  Alex VILLAPLANE|       C|     NULL|\n",
            "|    201|   1096|          MEX|   LUQUE Juan (MEX)|      S|           0|     Manuel ROSAS|    NULL|     NULL|\n",
            "|    201|   1096|          FRA|CAUDRON Raoul (FRA)|      S|           0|   Lucien LAURENT|    NULL|     G19'|\n",
            "|    201|   1096|          MEX|   LUQUE Juan (MEX)|      S|           0|        Jose RUIZ|    NULL|     NULL|\n",
            "|    201|   1096|          FRA|CAUDRON Raoul (FRA)|      S|           0|   Marcel CAPELLE|    NULL|     NULL|\n",
            "|    201|   1096|          MEX|   LUQUE Juan (MEX)|      S|           0|  Alfredo SANCHEZ|    NULL|     NULL|\n",
            "|    201|   1096|          FRA|CAUDRON Raoul (FRA)|      S|           0|Augustin CHANTREL|    NULL|     NULL|\n",
            "|    201|   1096|          MEX|   LUQUE Juan (MEX)|      S|           0|   Efrain AMEZCUA|    NULL|     NULL|\n",
            "+-------+-------+-------------+-------------------+-------+------------+-----------------+--------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Importar las bibliotecas necesarias\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# 1. Crear una sesión de Spark\n",
        "spark = SparkSession.builder.appName(\"WorldCupPlayersAnalysis\").getOrCreate()  # Obtener o crear la sesión de Spark\n",
        "\n",
        "# 2. Importar el archivo CSV y deducir el esquema\n",
        "# Se lee el archivo CSV con encabezado y se infiere el esquema automáticamente\n",
        "df = spark.read.csv(\"./WorldCupPlayers.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# 3. Visualizar los datos\n",
        "# Mostrar las primeras 5 filas del DataFrame para inspeccionar los datos\n",
        "print(\"Visualización de los datos:\")\n",
        "df.show(5)\n",
        "\n",
        "# 4. Verificar el tipo de datos de cada variable\n",
        "# Mostrar el esquema del DataFrame para conocer los tipos de datos de cada columna\n",
        "print(\"\\nEsquema del DataFrame:\")\n",
        "df.printSchema()\n",
        "\n",
        "# 5. Contar el número de registros\n",
        "# Contar cuántos registros hay en el DataFrame\n",
        "num_records = df.count()\n",
        "print(f\"\\nNúmero de registros: {num_records}\")\n",
        "\n",
        "# 6. Obtener los principales estadísticos de la columna \"Position\"\n",
        "# Usar la función describe() para obtener estadísticos como count, mean, stddev, min y max\n",
        "print(\"\\nEstadísticos de la columna 'Position':\")\n",
        "df.describe(\"Position\").show()\n",
        "\n",
        "# 7. Seleccionar y mostrar los \"Team initials\" diferentes y contar cuántos hay\n",
        "# Seleccionar los valores únicos de la columna \"Team Initials\"\n",
        "team_initials = df.select(\"Team Initials\").distinct()\n",
        "print(\"\\nValores únicos de 'Team Initials':\")\n",
        "team_initials.show()\n",
        "\n",
        "# Contar cuántos valores únicos hay en \"Team Initials\"\n",
        "num_team_initials = team_initials.count()\n",
        "print(f\"\\nNúmero de 'Team Initials' diferentes: {num_team_initials}\")\n",
        "\n",
        "# 8. Contar cuántos partidos con el ID de 1096 ha habido\n",
        "# Filtrar el DataFrame para contar los registros donde MatchID sea 1096\n",
        "num_matches_1096 = df.filter(df.MatchID == 1096).count()\n",
        "print(f\"\\nNúmero de partidos con el ID 1096: {num_matches_1096}\")\n",
        "\n",
        "# 9. Mostrar los datos donde la posición haya sido \"C\" y el evento sea \"G40\"\n",
        "# Filtrar el DataFrame para obtener registros donde Position sea \"C\" y Event sea \"G40\"\n",
        "filtered_data = df.filter((df.Position == \"C\") & (df.Event == \"G40\"))\n",
        "print(\"\\nDatos filtrados donde Position es 'C' y Event es 'G40':\")\n",
        "filtered_data.show()\n",
        "\n",
        "# 10. Utilizar Spark SQL para mostrar los registros donde el MatchID sea mayor o igual a 20\n",
        "# Registrar el DataFrame como una vista temporal para poder usar Spark SQL\n",
        "df.createOrReplaceTempView(\"world_cup_players\")\n",
        "\n",
        "# Ejecutar una consulta SQL para filtrar registros donde MatchID sea mayor o igual a 20\n",
        "result = spark.sql(\"SELECT * FROM world_cup_players WHERE MatchID >= 20\")\n",
        "print(\"\\nRegistros con MatchID mayor o igual a 20:\")\n",
        "result.show()\n",
        "\n",
        "# 11. Cerrar la sesión de Spark\n",
        "# Es importante cerrar la sesión de Spark al finalizar\n",
        "spark.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwlXPat85SRc"
      },
      "source": [
        "## EJERCICIO 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySES8yYI5SRc"
      },
      "source": [
        "A partir del archivo nombres.json, crea un DataFrame y realiza las siguientes operaciones:\n",
        "\n",
        "1. Crea una nueva columna (columna Mayor30) que indique si la persona es mayor de 30 años.\n",
        "2. Crea una nueva columna (columna FaltanJubilacion) que calcule cuantos años le faltan para jubilarse (supongamos que se jubila a los 67 años)\n",
        "3. Crea una nueva columna (columna Apellidos) que contenga XYZ (puedes utilizar la función lit)\n",
        "4. Elimina las columna Mayor30 y Apellidos.\n",
        "5. Crea una nueva columna (columna AnyoNac) con el año de nacimiento de cada persona (puedes utilizar la función current_date).\n",
        "6. Añade un id incremental para cada fila (campo Id) y haz que al hacer un show se vea en primer lugar (puedes utilizar la función monotonically_increasing_id) seguidos del Nombre, Edad, AnyoNac, FaltaJubilacion y Ciudad\n",
        "\n",
        "Al realizar los seis pasos, el resultado del DataFrame será similar a :\n",
        "``````\n",
        "+---+-------+----+-------+----------------+--------+\n",
        "| Id|Nombre |Edad|AnyoNac|FaltanJubilacion|  Ciudad|\n",
        "+---+-------+----+-------+----------------+--------+\n",
        "|  0|  Aitor|  45|   1977|              22|   Elche|\n",
        "|  1| Marina|  14|   2008|              53|Alicante|\n",
        "|  2|  Laura|  19|   2003|              48|   Elche|\n",
        "|  3|  Sonia|  45|   1977|              22|    Aspe|\n",
        "|  4|  Pedro|null|   null|            null|   Elche|\n",
        "+---+-------+----+-------+----------------+--------+\n",
        "``````"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpLo_k6g5SRc",
        "outputId": "4a0cebf1-589b-4053-ad62-db2740038016"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZhUS4RU5SRd"
      },
      "source": [
        "## EJERCICIO 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0VRuSPS5SRd"
      },
      "source": [
        "A partir del archivo VentasNulos.csv:\n",
        "\n",
        "1. Elimina las filas que tengan al menos 4 nulos.\n",
        "\n",
        "2. Con las filas restantes, sustituye:\n",
        "\n",
        "    * Los nombres nulos por Empleado\n",
        "    * Las ventas nulas por la media de las ventas de los compañeros (redondeado a entero).\n",
        "    ``````\n",
        "        media = df.groupBy().avg('Ventas')\n",
        "    ``````\n",
        "    * Los euros nulos por el valor del compañero que menos € ha ganado. (tras agrupar, puedes usar la función min)\n",
        "    * La ciudad nula por C.V. y el identificador nulo por XYZ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ma0jMrYh5SRe",
        "outputId": "efe5c87e-8e98-45c3-96e3-d44befd97f6f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62C3pGjg5SRe"
      },
      "source": [
        "## EJERCICIO 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kz8oZ4zB5SRe"
      },
      "source": [
        " A partir del archivo movies.tsv, crea una esquema de forma declarativa con los campos:\n",
        "\n",
        "* interprete de tipo string\n",
        "* pelicula de tipo string\n",
        "* anyo de tipo int\n",
        "\n",
        "Cada fila del fichero implica que el actor/actriz ha trabajado en dicha película en el año indicado.\n",
        "1. Una vez creado el esquema, carga los datos en un DataFrame.\n",
        "\n",
        "A continuación, mediante el DataFrame API:\n",
        "\n",
        "2. Muestra las películas en las que ha trabajado Murphy, Eddie (I).\n",
        "3. Muestra los intérpretes que aparecen tanto en Superman como en Superman II."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeFxQSdgbuti"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhZ9aGeq5SRf"
      },
      "source": [
        "## EJERCICIO 5\n",
        "Realiza las siguientes operaciones:\n",
        "* Carga el dataset de “data/stocks_price_final.csv”, con el esquema correcto de datos (tienes que crear tu el schema\").\n",
        "* Renombra la variable market.cap a market\n",
        "* Elimina la variable market\n",
        "* Muestra las filas donde el valor de \"open\" es nulo.\n",
        "* Elimina las filas donde el valor de \"open\" es nulo.\n",
        "* Para comprobar el punto anterior vuelve a mostrar las filas donde el valor de \"open\" es nulo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oawpRKQ55SRf",
        "outputId": "21b4b449-0fe5-480f-f9bd-7b3e2e1ff6f4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "CloneSAPA",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
